# -*- coding: utf-8 -*-
"""RegresionRegularizada.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UpwV50-r1wakvLrSHnn7NFacGd4gr4N-
"""

import pandas as pd
import numpy as np
from numpy import nan as NA
from sklearn import model_selection
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import sklearn.metrics as metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from math import sqrt
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
data = pd.read_csv('https://raw.githubusercontent.com/asepulvede/ModelacionSimulacion4/main/healthcare-dataset-stroke-data.csv')
data= pd.get_dummies(data, columns= ["gender"])
data= pd.get_dummies(data, columns= ["ever_married"])
data= pd.get_dummies(data, columns= ["work_type"])
data= pd.get_dummies(data, columns= ["Residence_type"])
data= pd.get_dummies(data, columns= ["smoking_status"])
data= data.fillna(method='ffill')
#features=data.drop(columns='stroke')
#target = data.loc[:,'stroke']
#oversample = SMOTE()
#features, target = oversample.fit_resample(features, target)
#features=pd.DataFrame(features)
#target=pd.DataFrame(target)
#data = pd.read_csv('https://raw.githubusercontent.com/asepulvede/ModelacionSimulacion4/main/healthcare-dataset-stroke-data.csv') #Dataset con outliers
data=data.drop(columns='id')
data= data.drop([ 'Residence_type_Urban', 'work_type_children', 'Residence_type_Rural','work_type_Self-employed', 'work_type_Private','work_type_Never_worked', 'work_type_Govt_job','ever_married_Yes','ever_married_No','gender_Other', 'gender_Male','gender_Female'], axis=1)
from sklearn.datasets import make_classification
from imblearn.under_sampling import RandomUnderSampler


target = ['stroke'] 

predictors = list(set(list(data.columns))-set(target))
data[predictors] = data[predictors]/data[predictors].max()


X = data[predictors].values
y = data[target].values
undersample = RandomUnderSampler(sampling_strategy='majority')

X_over, y_over = undersample.fit_resample(X, y)





def ridge(X_train,y_train):
  rr = Ridge(alpha=0.01)
  rr.fit(X_train, y_train) 
  betas=rr.coef_
  beta0=rr.intercept_
  return betas,beta0
 

def lasso(X_train,y_train):
  model_lasso = Lasso(alpha=0.01)
  model_lasso.fit(X_train, y_train) 
  betas=model_lasso.coef_
  beta0=model_lasso.intercept_
  return betas,beta0

def elastic(X_train,y_train):
   model_enet = ElasticNet(alpha = 0.01)
   model_enet.fit(X_train, y_train) 
   betas=model_enet.coef_
   beta0=model_enet.intercept_
   return betas,beta0

def sigmoid(betas, beta0, features):
    Xbetas = np.dot(features,betas.T)
    y = beta0 + Xbetas
    return 1 / (1 + np.exp(-y))

acc=[]
auc=[]
for i in range(100):
  X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.30)

  Betas, Beta0 = ridge(X_train,y_train)
  Prob = sigmoid(Betas, Beta0, X_test) 
  Prediction = np.zeros((len(X_test)), dtype=float)
  for i in range(len(X_test)):

    if Prob[i]>=0.5:
      Prediction[i]=1.0
    else:
      Prediction[i]=0.0

  fpr, tpr, threshold = metrics.roc_curve(y_test,Prediction)
  roc_auc = metrics.auc(fpr, tpr)
  auc.append(roc_auc)
  acc.append(accuracy_score(y_test, Prediction))

#print(acc)
#print(auc)

plt.plot(acc)
plt.xlabel('Iteraciones')
plt.ylabel('Puntaje')
plt.title('Accuracy Score por iteración Elastic')
plt.show()

plt.plot(auc,color='g')
plt.xlabel('Iteraciones')
plt.ylabel('Puntaje')
plt.title('AUC por iteración Elastic')
plt.show()