{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RegresiónLogística.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxvU8JpvHuTn",
        "outputId": "a2ab9e47-10a5-44ba-ebb8-1fcc9b348852"
      },
      "source": [
        "##KENDALL CORR\n",
        "\n",
        "###DATASET STROKE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import nan as NA\n",
        "#data = pd.read_csv('https://raw.githubusercontent.com/asepulvede/ModelacionSimulacion4/main/healthcare-dataset-stroke-data.csv')\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/asepulvede/ModelacionSimulacion4/main/healthcare-dataset-stroke-data.csv') #Dataset con outliers\n",
        "new_data= data.fillna(method='ffill')\n",
        "new_data2= pd.get_dummies(new_data, columns= [\"gender\"])\n",
        "new_data3= pd.get_dummies(new_data2, columns= [\"ever_married\"])\n",
        "new_data4= pd.get_dummies(new_data3, columns= [\"work_type\"])\n",
        "new_data5= pd.get_dummies(new_data4, columns= [\"Residence_type\"])\n",
        "new_data6= pd.get_dummies(new_data5, columns= [\"smoking_status\"])\n",
        "new_data6= new_data6.drop([ 'Residence_type_Urban', 'work_type_children', 'Residence_type_Rural','work_type_Self-employed', 'work_type_Private','work_type_Never_worked', 'work_type_Govt_job','ever_married_Yes','ever_married_No','gender_Other', 'gender_Male','gender_Female'], axis=1)\n",
        "new_data6=new_data6.drop(columns='id')\n",
        "\n",
        "\n",
        "## BALANCEAR DATOS\n",
        "x=new_data6.loc[new_data6['stroke']==0]\n",
        "m = x.sample(249)\n",
        "y=new_data6.loc[new_data6['stroke']==1]\n",
        "new_data6 = pd.concat([y,m],axis=0)\n",
        "\n",
        "##FEATURES STROKE\n",
        "\n",
        "features=new_data6.drop(columns='stroke')\n",
        "target = new_data6.iloc[:,2]\n",
        "\n",
        "##MATRIZ DE COVARIANZA ROBUSTA MÉTODOS\n",
        "from statistics import stdev\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "from statsmodels import robust\n",
        "from scipy.stats import kendalltau\n",
        "from scipy import stats\n",
        "\n",
        "def covariance(x,y):\n",
        "  coef, p = kendalltau(x,y)\n",
        "  VI = coef*(stdev(x)*stdev(y)) #Existe la opción de hacerlo con el MAD para que sea más robusto,\n",
        "  #Sin embargo, con nuestros datos esto resulta en una matriz singular (no invertible)\n",
        "  return VI\n",
        "\n",
        "def covarianceM(x):\n",
        "  covar = np.zeros((len(x.columns),len(x.columns)), dtype=float)\n",
        "  for i,j in np.ndindex(covar.shape): \n",
        "      VI=covariance(x.iloc[:,i],x.iloc[:,j])\n",
        "      covar[i,j] = VI\n",
        "  return covar\n",
        "\n",
        "##BETAS \n",
        "\n",
        "def betas(features, target):\n",
        "  cova = covarianceM(features)\n",
        "  Cxinv = np.linalg.inv(cova)\n",
        "  covars = np.zeros((len(features.columns)), dtype=float)\n",
        "  for i in range(len(features.columns)):\n",
        "    covars[i] = covariance(features.iloc[:,i],target)\n",
        "  Betas=np.dot(Cxinv,(covars.T))\n",
        "\n",
        "##BETA 0\n",
        "  promedio = target.mean()\n",
        "  Beta0 = promedio - np.dot(features.mean(axis=0),Betas)\n",
        "  return Betas, Beta0\n",
        "\n",
        "#Link function o función sigmoide\n",
        "def sigmoid(betas, beta0, features):\n",
        "    Xbetas = np.dot(features,betas)\n",
        "    y = beta0 + Xbetas\n",
        "    return 1 / (1 + np.exp(-y))\n",
        "Betas, Beta0 = betas(features,target)\n",
        "\n",
        "##Prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "auc = []\n",
        "#for i in range(1000):\n",
        "x_train, x_test, y_train, y_test=train_test_split(features,target)\n",
        "\n",
        "Betas, Beta0 = betas(x_train,y_train)\n",
        "Prob = sigmoid(Betas, Beta0, x_test) \n",
        "Prediction = np.zeros((len(x_test)), dtype=float)\n",
        "for i in range(len(x_test)):\n",
        "  if Prob[i]>=0.5:\n",
        "    Prediction[i]=1.0\n",
        "  else:\n",
        "    Prediction[i]=0.0\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test,Prediction)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "auc.append(roc_auc)\n",
        "acc = accuracy_score(y_test, Prediction)\n",
        "print(confusion_matrix(y_test,Prediction))\n",
        "print(acc)\n",
        "print(auc)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[92 17]\n",
            " [ 0 16]]\n",
            "0.864\n",
            "[0.9220183486238532]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43q53ecmKuD-",
        "outputId": "68362d2b-2a5d-455f-e596-5c1b8726965a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          age  hypertension  ...  smoking_status_never smoked  smoking_status_smokes\n",
            "0        67.0             0  ...                            0                      0\n",
            "1        61.0             0  ...                            1                      0\n",
            "2        80.0             0  ...                            1                      0\n",
            "3        49.0             0  ...                            0                      1\n",
            "4     46445.0             1  ...                            1                      0\n",
            "...       ...           ...  ...                          ...                    ...\n",
            "341      37.0             0  ...                            0                      0\n",
            "2153     54.0             0  ...                            0                      0\n",
            "421      12.0             0  ...                            0                      0\n",
            "2625     32.0             0  ...                            0                      0\n",
            "422      63.0             0  ...                            0                      0\n",
            "\n",
            "[498 rows x 22 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUZ8PLRm_bFN",
        "outputId": "430c1278-f365-4d83-ead1-4d4d34616ede"
      },
      "source": [
        "##NO-ROBUSTA\n",
        "\n",
        "###DATASET STROKE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import nan as NA\n",
        "#data = pd.read_csv('https://raw.githubusercontent.com/asepulvede/ModelacionSimulacion4/main/healthcare-dataset-stroke-data.csv')\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/asepulvede/ModelacionSimulacion4/main/healthcare-dataset-stroke-data.csv') #Dataset con outliers\n",
        "new_data= data.fillna(method='ffill')\n",
        "new_data2= pd.get_dummies(new_data, columns= [\"gender\"])\n",
        "new_data3= pd.get_dummies(new_data2, columns= [\"ever_married\"])\n",
        "new_data4= pd.get_dummies(new_data3, columns= [\"work_type\"])\n",
        "new_data5= pd.get_dummies(new_data4, columns= [\"Residence_type\"])\n",
        "new_data6= pd.get_dummies(new_data5, columns= [\"smoking_status\"])\n",
        "new_data6= new_data6.drop([ 'Residence_type_Urban', 'work_type_children', 'Residence_type_Rural','work_type_Self-employed', 'work_type_Private','work_type_Never_worked', 'work_type_Govt_job','ever_married_Yes','ever_married_No','gender_Other', 'gender_Male','gender_Female'], axis=1)\n",
        "new_data6=new_data6.drop(columns='id')\n",
        "\n",
        "\n",
        "## BALANCEAR DATOS\n",
        "x=new_data6.loc[new_data6['stroke']==0]\n",
        "m = x.sample(249)\n",
        "y=new_data6.loc[new_data6['stroke']==1]\n",
        "new_data6 = pd.concat([y,m],axis=0)\n",
        "\n",
        "##FEATURES STROKE\n",
        "\n",
        "features=new_data6.drop(columns='stroke')\n",
        "target = new_data6.iloc[:,2]\n",
        "\n",
        "##MATRIZ DE COVARIANZA ROBUSTA MÉTODOS\n",
        "from statistics import stdev\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "from statsmodels import robust\n",
        "from scipy.stats import kendalltau\n",
        "from scipy import stats\n",
        "\n",
        "def covariance(x,y):\n",
        "  coef, p = stats.pearsonr(x,y)\n",
        "  VI = coef*(stdev(x)*stdev(y)) #Existe la opción de hacerlo con el MAD para que sea más robusto,\n",
        "  #Sin embargo, con nuestros datos esto resulta en una matriz singular (no invertible)\n",
        "  return VI\n",
        "\n",
        "def covarianceM(x):\n",
        "  covar = np.zeros((len(x.columns),len(x.columns)), dtype=float)\n",
        "  for i,j in np.ndindex(covar.shape): \n",
        "      VI=covariance(x.iloc[:,i],x.iloc[:,j])\n",
        "      covar[i,j] = VI\n",
        "  return covar\n",
        "\n",
        "##BETAS \n",
        "\n",
        "def betas(features, target):\n",
        "  cova = covarianceM(features)\n",
        "  Cxinv = np.linalg.inv(cova)\n",
        "  covars = np.zeros((len(features.columns)), dtype=float)\n",
        "  for i in range(len(features.columns)):\n",
        "    covars[i] = covariance(features.iloc[:,i],target)\n",
        "  Betas=np.dot(Cxinv,(covars.T))\n",
        "\n",
        "##BETA 0\n",
        "  promedio = target.mean()\n",
        "  Beta0 = promedio - np.dot(features.mean(axis=0),Betas)\n",
        "  return Betas, Beta0\n",
        "\n",
        "#Link function o función sigmoide\n",
        "def sigmoid(betas, beta0, features):\n",
        "    Xbetas = np.dot(features,betas)\n",
        "    y = beta0 + Xbetas\n",
        "    return 1 / (1 + np.exp(-y))\n",
        "Betas, Beta0 = betas(features,target)\n",
        "\n",
        "##Prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "auc = []\n",
        "#for i in range(1000):\n",
        "x_train, x_test, y_train, y_test=train_test_split(features,target)\n",
        "\n",
        "Betas, Beta0 = betas(x_train,y_train)\n",
        "Prob = sigmoid(Betas, Beta0, x_test) \n",
        "Prediction = np.zeros((len(x_test)), dtype=float)\n",
        "for i in range(len(x_test)):\n",
        "  if Prob[i]>=0.5:\n",
        "    Prediction[i]=1.0\n",
        "  else:\n",
        "    Prediction[i]=0.0\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test,Prediction)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "auc.append(roc_auc)\n",
        "acc = accuracy_score(y_test, Prediction)\n",
        "print(confusion_matrix(y_test,Prediction))\n",
        "print(acc)\n",
        "print(auc)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[74 38]\n",
            " [ 0 13]]\n",
            "0.696\n",
            "[0.8303571428571428]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxmCJyVP-9bw",
        "outputId": "e4dc9f3f-a796-4e42-8d90-025a24174f9b"
      },
      "source": [
        "##SPEARMAN CORR\n",
        "\n",
        "###DATASET STROKE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import nan as NA\n",
        "#data = pd.read_csv('https://raw.githubusercontent.com/asepulvede/ModelacionSimulacion4/main/healthcare-dataset-stroke-data.csv')\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/asepulvede/ModelacionSimulacion4/main/healthcare-dataset-stroke-data.csv') #Dataset con outliers\n",
        "new_data= data.fillna(method='ffill')\n",
        "new_data2= pd.get_dummies(new_data, columns= [\"gender\"])\n",
        "new_data3= pd.get_dummies(new_data2, columns= [\"ever_married\"])\n",
        "new_data4= pd.get_dummies(new_data3, columns= [\"work_type\"])\n",
        "new_data5= pd.get_dummies(new_data4, columns= [\"Residence_type\"])\n",
        "new_data6= pd.get_dummies(new_data5, columns= [\"smoking_status\"])\n",
        "new_data6= new_data6.drop([ 'Residence_type_Urban', 'work_type_children', 'Residence_type_Rural','work_type_Self-employed', 'work_type_Private','work_type_Never_worked', 'work_type_Govt_job','ever_married_Yes','ever_married_No','gender_Other', 'gender_Male','gender_Female'], axis=1)\n",
        "new_data6=new_data6.drop(columns='id')\n",
        "\n",
        "\n",
        "## BALANCEAR DATOS\n",
        "x=new_data6.loc[new_data6['stroke']==0]\n",
        "m = x.sample(249)\n",
        "y=new_data6.loc[new_data6['stroke']==1]\n",
        "new_data6 = pd.concat([y,m],axis=0)\n",
        "\n",
        "##FEATURES STROKE\n",
        "\n",
        "features=new_data6.drop(columns='stroke')\n",
        "target = new_data6.iloc[:,2]\n",
        "\n",
        "##MATRIZ DE COVARIANZA ROBUSTA MÉTODOS\n",
        "from statistics import stdev\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "from statsmodels import robust\n",
        "from scipy.stats import kendalltau\n",
        "from scipy import stats\n",
        "\n",
        "def covariance(x,y):\n",
        "  coef, p = spearmanr(x,y)\n",
        "  VI = coef*(stdev(x)*stdev(y)) #Existe la opción de hacerlo con el MAD para que sea más robusto,\n",
        "  #Sin embargo, con nuestros datos esto resulta en una matriz singular (no invertible)\n",
        "  return VI\n",
        "\n",
        "def covarianceM(x):\n",
        "  covar = np.zeros((len(x.columns),len(x.columns)), dtype=float)\n",
        "  for i,j in np.ndindex(covar.shape): \n",
        "      VI=covariance(x.iloc[:,i],x.iloc[:,j])\n",
        "      covar[i,j] = VI\n",
        "  return covar\n",
        "\n",
        "##BETAS \n",
        "\n",
        "def betas(features, target):\n",
        "  cova = covarianceM(features)\n",
        "  Cxinv = np.linalg.inv(cova)\n",
        "  covars = np.zeros((len(features.columns)), dtype=float)\n",
        "  for i in range(len(features.columns)):\n",
        "    covars[i] = covariance(features.iloc[:,i],target)\n",
        "  Betas=np.dot(Cxinv,(covars.T))\n",
        "\n",
        "##BETA 0\n",
        "  promedio = target.mean()\n",
        "  Beta0 = promedio - np.dot(features.mean(axis=0),Betas)\n",
        "  return Betas, Beta0\n",
        "\n",
        "#Link function o función sigmoide\n",
        "def sigmoid(betas, beta0, features):\n",
        "    Xbetas = np.dot(features,betas)\n",
        "    y = beta0 + Xbetas\n",
        "    return 1 / (1 + np.exp(-y))\n",
        "Betas, Beta0 = betas(features,target)\n",
        "\n",
        "##Prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "auc = []\n",
        "#for i in range(1000):\n",
        "x_train, x_test, y_train, y_test=train_test_split(features,target)\n",
        "\n",
        "Betas, Beta0 = betas(x_train,y_train)\n",
        "Prob = sigmoid(Betas, Beta0, x_test) \n",
        "Prediction = np.zeros((len(x_test)), dtype=float)\n",
        "for i in range(len(x_test)):\n",
        "  if Prob[i]>=0.5:\n",
        "    Prediction[i]=1.0\n",
        "  else:\n",
        "    Prediction[i]=0.0\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test,Prediction)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "auc.append(roc_auc)\n",
        "acc = accuracy_score(y_test, Prediction)\n",
        "print(confusion_matrix(y_test,Prediction))\n",
        "print(acc)\n",
        "print(auc)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[59 59]\n",
            " [ 0  7]]\n",
            "0.528\n",
            "[0.75]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}